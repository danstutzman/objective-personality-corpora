I try to convince people to slow down
slow down
AI to regulate AI this was futile I
tried for years this you nobody seen in
a movie over this robots take over it
you're freaking me out
nobody listened nobody listened no one
are people more inclined to listen today
it seems like an issue that's brought up
more often over the last few years than
it was maybe five ten years ago it
seemed like science fiction maybe they
will so far they haven't I think people
don't be like the normally of the way
that regulations work it's very slow
very slow indeed so usually will be
something some new technology it will
cause damage or death there will be an
outcry there will be an investigation
years will pass there will be some sort
of insight committee they will be
rulemaking then there will be oversight
eventually regulations this all takes
many years this is the normal course of
things if you look at say automotive
regulations how long did it take for
seatbelts to be to be implemented to be
required you know the order industry
fort seatbelts I think for more than a
decade successfully fought any
regulations on seatbelts even though the
numbers were extremely obvious if you
had a seatbelts on
you would be far less likely to die will
be seriously injured unequivocal and the
industry fought this for years
successfully eventually after many many
people died regulators insisted on
seatbelts
if this is a this timeframe is not
relevant to AI
you can't take 10 years from the point
of which is dangerous it's too late and
you feel like this is decades away or
years away from being too late if you
have this fatalistic attitude and you
feel like it's going we're in a almost
like a doomsday countdown it's not
necessarily a doomsday countdown it's
it's a out-of-control countdown out of
control yeah people call it the
singularity and that's that's probably
gonna be the thing about it it's a
single error it's hard to predict like a
black hole what happens past the event
horizon right so once it's implemented
it's very different cuz it what do you
get out of the bottle what's gonna
happen and it will be able to improve
itself yes that's where it gets spooky
right the idea that it can do thousands
of years of innovation we're very very
quickly yeah and then we'll be just
ridiculous ridiculous we will be like
this ridiculous
biological shitting pissing thing trying
to stop the gods no stop we like we like
living with a finite lifespan and and
watching you know Norman Rockwell
paintings it could be terrible and it
could be great it's not clear right but
what one thing is for sure we will not
control it do you think that it's likely
that we will merge somehow or another
with this sort of technology and it'll
augment what we are now or do you think
it will replace us well that's the snart
emerge scenario with AI is the one that
seems like probably the best like for us
yes like if you if you can't beat it
join it that's yeah you know
so from a long-term existential
standpoint that's like the purpose of
neuro-link is to create a high bandwidth
interface to the brain such that we can
be symbolic with AI because we have a
bandwidth problem
you just can't communicate through your
fingers it's too slow and where's neural
link at right now I think we'll have
something interesting to announce in a
few months that's at least an order of
magnitude better than anything else
probably I think better than probably
anyone thinks as possible how much can
you talk about that right now I don't
jump the gun on that but what's like the
ultimate what's what's the idea behind
like what are you trying to accomplish
with it what would you like best-case
scenario I think this case scenario we
effectively merge with AI where we AI
serves as a tertiary cognition layer
where we've got the limbic system kind
of the primitive brain essentially
you've got the cortex so you're
currently in a symbiotic relationship
with your cortex and limbic system are
in a somatic relationship and generally
people like their cortex and they like
the Olympic system I haven't met anyone
who wants to delete their limbic system
or delete their cortex everybody seems
sort of like both and the cortex is
mostly in service to the limbic system
people may think that that that their
that the thinking part of themselves is
in charge but it's mostly their limbic
system that's in charge and the cortex
is trying to make the limbic system
happy that's what most of that computing
power is aren't towards how can I make
the limbic system happy that's what it's
trying to do now if we do have a third
layer which is the AI extension of
yourself that is also somatic and
there's enough bandwidth between the
cortex and the AI extension of yourself
such that the AI doesn't if
facto separate then that could be a good
outcome that could be quite a positive
outcome for the future so instead of
replacing us it will radically change
our capabilities yes it will enable
anyone who wants to have super human
cognition anyone who wants this is not a
matter of earning power because your
earning power would be vastly greater
after you do it so it's just like anyone
who once can just do it in theory that's
the theory and and if that's the case
then and let's say billions of people do
it then the outcome for Humanity will be
the sum of of human will the sum of
billions of people's desire for the
future and that billions of people with
enhanced cognitive ability radically
enhance yes and that which would be it
but how much different than people today
look if you if you had to explain it to
a person who didn't really not
understand what you're saying
how much different are you talking about
when you say radically improved like
what do you mean you mean mine read when
read it will be difficult to to really
appreciate the difference it's kind like
how much smarter are you with a phone or
computer than without it's your vastly
smarter actually you know you can answer
any question which if you're connected
to the internet you know answer any
question pretty much instantly any
calculation the that your phone's memory
is essentially perfect
you can remember flawlessly go for your
phone can remember videos pictures and
everything perfectly
that's the that your phone is already an
extension of you you're already a cyborg
you don't even almost will in rise they
are already a cyborg it that phone is an
extension of yourself it's just that
the the data rate the rate at which the
communication rate between you and the
cybernetic extension of yourself that is
your phone and computer is slow it's
very slow and that that it's like a tiny
straw of information flow between your
biological self and your digital self
and we need to make that tiny straw like
a giant river a huge high bandwidth
interface it's an interface problem data
rate problem so the data rate problem
that I think I think we can hang on to
human-machine symbiosis through the long
term and then people may decide that
they want to retain their biological
self or not I think they'll probably
choose to retain develop biological self
versus some sort of Ray Kurzweil
scenario where they download themselves
into a computer you will be essentially
snapshot it into a computer at any time
if your biological self dies you could
just probably just upload into a new
unit literally that down the rabbit hole
grab that sucker give me some of that
this is too freaky see if I was thinking
about this for a long time by the way I
believe yeah if I was talking to one
line cheers by the way chairs yeah this
is great whiskey thank you
Underwood's came from who brought this
to us trying to remember somebody gave
it to us old camp whoever goes Thanks
good yeah it is good um this is just
inevitable again going back to your when
you decided to be half of this
fatalistic viewpoints so you weren't you
tried to warn people you talked about
this pretty extensively I've read
several interviews where you talked
about this and then you just sort of
just said okay it just is well it's just
and you in a way you're by communicating
the potential fear I mean for sure
you're you're getting the warning out to
some people yeah yeah I mean if I was
really going on
the warning quite quite loud morning
everyone I could you've met with Obama
and just for one reason look just about
AI yes and what did he say so what about
Hillary worry about her first
no I he listened he certainly listened
I met with Congress I met with I was out
of meeting of all 50 governors and
talked about just a AI danger and I
talked to everyone I could no one seemed
to realize where this was going
is it that or do they just assume that
someone smarter than them was already
taking care of it because when people
hear about something like AI thought
it's almost abstract it's almost it's
almost like it's so it's so hard to wrap
your head around it by the time it
already happens it'll be too late
yeah I think they didn't quite her to
understand it or didn't think it was
near term or not sure what to do about
it
and I said like you know an obvious
thing to do is to just establish a
committee government committee to gain
insight you know before before you
oversight before you do make regulations
you should like to try to understand
what's going on and then if you have a
insight committee then the once they
learn what's going on get up to speed
then they can make maybe some rules will
propose some rules and and that would be
